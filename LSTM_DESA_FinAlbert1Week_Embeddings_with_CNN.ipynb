{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_DESA_FinAlbert1Week_Embeddings_with_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alvarezpablo/NLP-Stocks-Price-Prediction/blob/main/LSTM_DESA_FinAlbert1Week_Embeddings_with_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNUWmp-Z3VnV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuración para la ejecución"
      ],
      "metadata": {
        "id": "5lXOBb02Btcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#empresa = 'NETFLIX'\n",
        "#empresa = 'AMAZON'\n",
        "#empresa = 'APPLE'\n",
        "#empresa = 'GOOGLE'\n",
        "#empresa = 'ACME'\n",
        "\n",
        "empresa = 'TESLA'\n",
        "#empresa = 'FACEBOOK'\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "kL7ZtmCgByvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rutinas"
      ],
      "metadata": {
        "id": "8URhp_cPCAPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convierte los datos de entrada en una matriz con la ventana de tiempo\n",
        "def createDSWindows(dataset, ventana):\n",
        "  dataX, dataY, a = [], [], []\n",
        "  for i in range(len(dataset)-ventana-1):\n",
        "    a = dataset[i:(i+ventana), 1]\n",
        "    b = dataset[i, 0]\n",
        "    d = dataset[i,3]\n",
        "    c = np.concatenate((b,a), axis=None)\n",
        "    c = np.concatenate((c,d), axis=None)\n",
        "    dataX.append(c)\n",
        "    dataY.append(dataset[i + ventana, 1])\n",
        "  \n",
        "  return np.array(dataX), np.array(dataY)\n",
        "\n",
        "#retorna el proximo día (desde una fecha) sin considerar fines de semana \n",
        "def nextDay(fecha):\n",
        "  proximo = str((datetime.strptime(fecha,\"%Y-%m-%d\")+timedelta(days=+1)).strftime(\"%Y-%m-%d\"))\n",
        "  dia = datetime.strptime(proximo,\"%Y-%m-%d\").weekday()\n",
        "  if dia == 5:\n",
        "    proximo = str((datetime.strptime(fecha,\"%Y-%m-%d\")+timedelta(days=+3)).strftime(\"%Y-%m-%d\"))\n",
        "  elif dia == 6:\n",
        "    proximo = str((datetime.strptime(fecha,\"%Y-%m-%d\")+timedelta(days=+2)).strftime(\"%Y-%m-%d\"))\n",
        "  else:\n",
        "    proximo = str((datetime.strptime(fecha,\"%Y-%m-%d\")+timedelta(days=+1)).strftime(\"%Y-%m-%d\"))\n",
        "  return proximo\n",
        "\n",
        "def getPolaridad(fecha, dataframe, delta):\n",
        "  proximo = str((datetime.strptime(fecha,\"%Y-%m-%d\")+timedelta(days=+delta)).strftime(\"%Y-%m-%d\"))\n",
        "  df = dataframe\n",
        "  df = df.set_index('Date')\n",
        "  try:\n",
        "    polaridad = df.loc[[proximo], ['label']]\n",
        "  except:\n",
        "    return getPolaridad(fecha, dataframe, delta-1)\n",
        "  return polaridad.iloc[0,0]\n",
        "\n",
        "def setRows(dataframe):\n",
        "  fecha = []\n",
        "  polaridad = []\n",
        "  valor = []\n",
        "  vsemana = []\n",
        "  mensajes = []\n",
        "  for i in range(len(dataframe)):\n",
        "    f = dataframe.iloc[i,0]\n",
        "    p = dataframe.iloc[i,1]\n",
        "    v = dataframe.iloc[i,2]\n",
        "    vs = dataframe.iloc[i,3]\n",
        "    m = dataframe.iloc[i,4]\n",
        "    try:\n",
        "      b = dataframe.iloc[i+1,0]\n",
        "      next = nextDay(f)\n",
        "      if next == b:\n",
        "        fecha.append(f)\n",
        "        polaridad.append(p)\n",
        "        valor.append(v)\n",
        "        vsemana.append(vs)\n",
        "        mensajes.append(m)\n",
        "      else: #este caso se da cuando en el dataset no esta el día; feriado\n",
        "        fecha.append(f)\n",
        "        fecha.append(next)\n",
        "        polaridad.append(p)\n",
        "        valor.append(v)\n",
        "        vsemana.append(vs)\n",
        "        mensajes.append(m)\n",
        "        polaridad.append(getPolaridad(next,dataframe,7))\n",
        "        valor.append(v)\n",
        "        vsemana.append(vs)\n",
        "        mensajes.append(m)\n",
        "    except: #este caso se da cuando en el dataset no está la polaridad de la fecha que se busca, en ese caso, se usa la polaridad anterior\n",
        "      fecha.append(f)\n",
        "      polaridad.append(p)\n",
        "      valor.append(v)\n",
        "      vsemana.append(vs)\n",
        "      mensajes.append(m)\n",
        "    \n",
        "    frame = {'Fecha':fecha, 'Polaridad':polaridad, 'Valor':valor, 'VSemana':vsemana, 'Mensajes':mensajes}\n",
        "    df = pd.DataFrame(frame)\n",
        "    df = df.set_index('Fecha')\n",
        "\n",
        "  return df\n",
        "\n",
        "def getNombreArchivo(accion):\n",
        "  empresa = ['TESLA', 'GOOGLE', 'FACEBOOK', 'APPLE', 'AMAZON', 'NETFLIX']\n",
        "  archivo = ['TSLA_label2.1.csv','GOOGL_label2.1.csv','FB_label2.1.csv','AAPL_label2.1.csv','AMZN_label2.1.csv','NFLX_label2.1.csv']\n",
        "  frame = {'Empresa':empresa, 'Archivo':archivo}\n",
        "  df =pd.DataFrame(frame)\n",
        "  df = df.set_index('Empresa')\n",
        "  archivo = df.loc[[accion],['Archivo']].values[0][0]\n",
        "  return archivo\n",
        "\n",
        "def mean_directional_accuracy(actual: np.ndarray, predicted: np.ndarray):\n",
        "  return np.mean((np.sign(actual[1:] - actual[:-1]) == np.sign(predicted[1:] - predicted[:-1])).astype(int))"
      ],
      "metadata": {
        "id": "ZKSBvkKdKxKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparación del dataset"
      ],
      "metadata": {
        "id": "TbAYUHTmBNCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fix random seed\n",
        "np.random.seed(7)\n",
        "\n",
        "# carga del dataset\n",
        "drive.mount('/drive')\n",
        "%cd '/gdrive/MyDrive/Magister IA/Tesis/Data/'\n",
        "\n",
        "%cd '/content/drive/MyDrive/MIA/Tesis/Data/'\n",
        "\n",
        "archivo = getNombreArchivo(empresa)\n",
        "df = pd.read_csv(archivo, index_col=False)\n",
        "df.drop(df[df['Date'] < '2018-07-20'].index, inplace=True)\n",
        "df.drop(df[df['Date'] > '2020-06-26'].index, inplace=True)\n",
        "#df = df.drop(['symbol','message','datetime','user','message_id','Time', 'stock_price_1week'], axis='columns')\n",
        "#df = df.drop(['symbol','message','datetime','user','message_id','Time'], axis='columns')\n",
        "df = df.drop(['symbol','datetime','user','message_id','Time'], axis='columns')\n",
        "#df.reset_index(level=0, inplace=True)\n",
        "\n",
        "df=df.groupby(['Date', 'label', 'stock_price', 'stock_price_1week'])['message'].apply(' '.join).reset_index()\n",
        "#df = df.set_index('Date')\n",
        "#feriado = df.loc[['2019-01-01'], ['label', 'message']]\n",
        "#feriado\n",
        "#df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBJ3JSwXKmhV",
        "outputId": "9cb5a53b-90f9-400c-c44e-eed283cdbe14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/MyDrive/Magister IA/Tesis/Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_data=train_data.groupby(['symbol','Date', 'label', 'stock_price', 'stock_price_1week'])['message'].apply(' '.join).reset_index()\n",
        "\n",
        "\n",
        "#df = df.groupby(by=['Date']).mean()\n",
        "df['label'] = df['label'].map({-1:0, 1:1, 0:0}, na_action=None)\n",
        "#df.reset_index(level=0, inplace=True)\n",
        "\n",
        "\n",
        "# se consideran 5 días por semana, ya que en el data set no están los fines de semana\n",
        "dias = 5\n",
        "#la ventana debería ser igual a días. Sin embargo, hay un dato adicional en el dataset; que es la polaridad. Por eso se agrega 1 al tamaño de la ventana \n",
        "ventana = dias+1\n",
        "\n",
        "newDF = setRows(df)\n",
        "newDF.isnull().sum()\n",
        "#feriado = newDF.loc[['2018-12-31','2019-01-01','2019-01-02'], ['Valor', 'Polaridad','VSemana', 'Mensajes']]\n",
        "#feriado\n",
        "newDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "oe_iVEcUh_wq",
        "outputId": "5285ae59-c310-40df-b98f-d6ebe00c3796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Polaridad</th>\n",
              "      <th>Valor</th>\n",
              "      <th>VSemana</th>\n",
              "      <th>Mensajes</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fecha</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2018-07-20</th>\n",
              "      <td>0</td>\n",
              "      <td>62.716000</td>\n",
              "      <td>59.436001</td>\n",
              "      <td>tsla shorts nutso mad getting good tsla crown ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-07-23</th>\n",
              "      <td>0</td>\n",
              "      <td>60.639999</td>\n",
              "      <td>58.034000</td>\n",
              "      <td>tsla wait 4 announcement bmw toyota saying adv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-07-24</th>\n",
              "      <td>0</td>\n",
              "      <td>59.486000</td>\n",
              "      <td>59.627998</td>\n",
              "      <td>39 say even lack insight comprehend insult goo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-07-25</th>\n",
              "      <td>0</td>\n",
              "      <td>61.748001</td>\n",
              "      <td>60.167999</td>\n",
              "      <td>tsla stock within correction showing 5 swings ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-07-26</th>\n",
              "      <td>1</td>\n",
              "      <td>61.330002</td>\n",
              "      <td>69.907997</td>\n",
              "      <td>pypl twtr tsla msft teva gs tsla stayed headli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-06-19</th>\n",
              "      <td>0</td>\n",
              "      <td>200.179993</td>\n",
              "      <td>191.947998</td>\n",
              "      <td>tsla brk tsla look yah catch tsla hey doin tsl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-06-22</th>\n",
              "      <td>1</td>\n",
              "      <td>198.863998</td>\n",
              "      <td>201.869995</td>\n",
              "      <td>tsla tesla cfo live webcam tsla seriously bull...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-06-23</th>\n",
              "      <td>1</td>\n",
              "      <td>200.356003</td>\n",
              "      <td>215.962006</td>\n",
              "      <td>tsla trouble staying north 100 tsla give lil n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-06-24</th>\n",
              "      <td>1</td>\n",
              "      <td>192.169998</td>\n",
              "      <td>223.925995</td>\n",
              "      <td>msft tsla ohh man I buy 70 k sucker tmrw promi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-06-25</th>\n",
              "      <td>1</td>\n",
              "      <td>197.195999</td>\n",
              "      <td>241.731995</td>\n",
              "      <td>spy aal azul gol tsla powell press activated 4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>505 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Polaridad  ...                                           Mensajes\n",
              "Fecha                  ...                                                   \n",
              "2018-07-20          0  ...  tsla shorts nutso mad getting good tsla crown ...\n",
              "2018-07-23          0  ...  tsla wait 4 announcement bmw toyota saying adv...\n",
              "2018-07-24          0  ...  39 say even lack insight comprehend insult goo...\n",
              "2018-07-25          0  ...  tsla stock within correction showing 5 swings ...\n",
              "2018-07-26          1  ...  pypl twtr tsla msft teva gs tsla stayed headli...\n",
              "...               ...  ...                                                ...\n",
              "2020-06-19          0  ...  tsla brk tsla look yah catch tsla hey doin tsl...\n",
              "2020-06-22          1  ...  tsla tesla cfo live webcam tsla seriously bull...\n",
              "2020-06-23          1  ...  tsla trouble staying north 100 tsla give lil n...\n",
              "2020-06-24          1  ...  msft tsla ohh man I buy 70 k sucker tmrw promi...\n",
              "2020-06-25          1  ...  spy aal azul gol tsla powell press activated 4...\n",
              "\n",
              "[505 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = newDF.values\n",
        "ds = createDSWindows(dataset, dias)\n",
        "ds"
      ],
      "metadata": {
        "id": "K6B8lAALrsx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = newDF.values\n",
        "dataset = dataset.astype('float32')\n",
        "\n",
        "\n",
        "# split train y test sets\n",
        "train_size = int(len(dataset) * 0.67)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "\n",
        "# reshape para la ventana\n",
        "trainX, trainY = createDSWindows(train, dias)\n",
        "testX, testY = createDSWindows(test, dias)\n",
        "\n",
        "# normalización de los sub-datasets\n",
        "scalerTrX = MinMaxScaler(feature_range=(0, 1))\n",
        "scalerTrY = MinMaxScaler(feature_range=(0, 1))\n",
        "scalerTeX = MinMaxScaler(feature_range=(0, 1))\n",
        "scalerTeY = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "trainX = scalerTrX.fit_transform(trainX)\n",
        "testX = scalerTeX.fit_transform(testX)\n",
        "\n",
        "trainY = trainY.reshape(-1,1)\n",
        "testY = testY.reshape(-1,1)\n",
        "\n",
        "trainY = scalerTrY.fit_transform(trainY)\n",
        "testY = scalerTeY.fit_transform(testY)\n",
        "\n",
        "trainY = trainY.flatten('F')\n",
        "testY = testY.flatten('F')\n",
        "\n",
        "# reshape [samples, time steps, features]\n",
        "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
        "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
        "\n",
        "trainX"
      ],
      "metadata": {
        "id": "n3soLRmP4TjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuración y ejecución de la LSTM"
      ],
      "metadata": {
        "id": "8quknDSEBX7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "model = Sequential()\n",
        "model.add(LSTM(units = 100, return_sequences = True, batch_input_shape=(batch_size, ventana, 1)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units = 100, return_sequences = True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units = 100, return_sequences = True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units = 100))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units = 1))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "history = model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "N-yoKldz5ppd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultados"
      ],
      "metadata": {
        "id": "BSEdT_vUCZEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history.history['loss'], label='Entrenamiento')\n",
        "plt.title('Curva de Pérdida '+empresa)\n",
        "plt.xlabel('épocas')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dqCTMZlFItEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicciones\n",
        "trainPredict = model.predict(trainX, batch_size=batch_size)\n",
        "model.reset_states()\n",
        "testPredict = model.predict(testX, batch_size=batch_size)\n",
        "\n",
        "# se invierten las predicciones\n",
        "trainPredict = scalerTrY.inverse_transform(trainPredict)\n",
        "trainYY = scalerTrY.inverse_transform([trainY])\n",
        "testPredict = scalerTeY.inverse_transform(testPredict)\n",
        "testYY = scalerTeY.inverse_transform([testY])\n",
        "\n",
        "\n",
        "# mean absolute error\n",
        "maeTr = mean_absolute_error(trainYY[0], trainPredict[:,0])\n",
        "print('Train MAE score: %.2f' % maeTr)\n",
        "maeTe = mean_absolute_error(testYY[0], testPredict[:,0])\n",
        "print('Test MAE score: %.2f' % maeTe)\n",
        "\n",
        "# mean squared error\n",
        "mseTr = mean_squared_error(trainYY[0], trainPredict[:,0])\n",
        "print('\\nTrain MSE score: %.2f' % mseTr)\n",
        "mseTe = mean_squared_error(testYY[0], testPredict[:,0])\n",
        "print('Test MSE score: %.2f' % mseTe)\n",
        "\n",
        "# root mean squared error\n",
        "trainScore = math.sqrt(mean_squared_error(trainYY[0], trainPredict[:,0]))\n",
        "print('\\nTrain RMSE score: %.2f' % (trainScore))\n",
        "testScore = math.sqrt(mean_squared_error(testYY[0], testPredict[:,0]))\n",
        "print('Test RMSE score: %.2f' % (testScore))\n",
        "\n",
        "# mean directional accuracy\n",
        "mda = mean_directional_accuracy(testYY[0], testPredict)\n",
        "print('\\nTest MDA score: ', \"{:.0%}\".format(mda))"
      ],
      "metadata": {
        "id": "46kLP9nlwAp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transformación para graficar los resultados\n",
        "i = 1\n",
        "columna = [fila[i] for fila in dataset]\n",
        "ds = np.array(columna)\n",
        "ds = ds.reshape(-1,1)\n",
        "\n",
        "trainPredictPlot = np.empty_like(ds)\n",
        "trainPredictPlot[:, :] = np.nan\n",
        "trainPredictPlot[dias:len(trainPredict)+dias, :] = trainPredict\n",
        "\n",
        "testPredictPlot = np.empty_like(ds)\n",
        "testPredictPlot[:, :] = np.nan\n",
        "testPredictPlot[len(trainPredict)+(dias*2)+1:len(ds)-1, :] = testPredict\n",
        "\n",
        "# plot de los datos de entrada y las predicciones\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(ds, label='Real')\n",
        "plt.title('Curva de entrenamiento y test '+empresa)\n",
        "plt.plot(trainPredictPlot, label=\"Entrenamiento\")\n",
        "plt.plot(testPredictPlot, label=\"Test\")\n",
        "plt.axvline(x=trainPredict.shape[0]+dias, c='r', linestyle='--')\n",
        "plt.xlabel('días')\n",
        "plt.ylabel('valor de la acción')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7wDWHCKpiL8e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}